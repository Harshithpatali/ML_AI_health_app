{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f9350ef2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Stroke dataset encoded, normalized, and saved as stroke_processed.csv\n",
      "Fitting 5 folds for each of 96 candidates, totalling 480 fits\n",
      "[LightGBM] [Info] Number of positive: 1564, number of negative: 3889\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000481 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1586\n",
      "[LightGBM] [Info] Number of data points in the train set: 5453, number of used features: 16\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.286815 -> initscore=-0.910905\n",
      "[LightGBM] [Info] Start training from score -0.910905\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "\n",
      "ðŸ§  Best Parameters: {'model__learning_rate': 0.1, 'model__max_depth': 3, 'model__min_child_samples': 20, 'model__n_estimators': 100, 'model__num_leaves': 31, 'model__subsample': 0.7}\n",
      "\n",
      "ðŸ§  Cross-Validation F1-Macro Score: 0.566 Â± 0.011\n",
      "\n",
      "ðŸ§  Cross-Validation ROC AUC Score: 0.803 Â± 0.013\n",
      "\n",
      "ðŸ§  Feature Importances:\n",
      "                            feature  importance\n",
      "0                              age    0.301724\n",
      "4                      gender_Male    0.117816\n",
      "9             Residence_type_Urban    0.102011\n",
      "6                work_type_Private    0.070402\n",
      "12           smoking_status_smokes    0.061782\n",
      "5                 ever_married_Yes    0.058908\n",
      "14         bmi_category_overweight    0.051724\n",
      "11     smoking_status_never smoked    0.045977\n",
      "3                 age_hypertension    0.044540\n",
      "7          work_type_Self-employed    0.034483\n",
      "10  smoking_status_formerly smoked    0.027299\n",
      "13             bmi_category_normal    0.024425\n",
      "15              bmi_category_obese    0.022989\n",
      "2                    heart_disease    0.014368\n",
      "1                     hypertension    0.014368\n",
      "8               work_type_children    0.007184\n",
      "\n",
      "ðŸ§  Stroke Model Performance (Default Threshold):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.89      0.92       972\n",
      "           1       0.14      0.36      0.20        50\n",
      "\n",
      "    accuracy                           0.86      1022\n",
      "   macro avg       0.55      0.62      0.56      1022\n",
      "weighted avg       0.92      0.86      0.89      1022\n",
      "\n",
      "\n",
      "ðŸ§  Confusion Matrix (Default Threshold):\n",
      "[[861 111]\n",
      " [ 32  18]]\n",
      "\n",
      "ðŸ§  Stroke Model with Adjusted Threshold (Recall >= 0.65):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.81      0.88       972\n",
      "           1       0.15      0.66      0.24        50\n",
      "\n",
      "    accuracy                           0.80      1022\n",
      "   macro avg       0.56      0.73      0.56      1022\n",
      "weighted avg       0.94      0.80      0.85      1022\n",
      "\n",
      "\n",
      "ðŸ§  Confusion Matrix (Adjusted Threshold):\n",
      "[[783 189]\n",
      " [ 17  33]]\n",
      "Optimal Threshold: 0.395\n",
      "ROC AUC Score: 0.792\n",
      "âœ… Precision-Recall curve saved as precision_recall_curve.png\n",
      "âœ… Optimized stroke model saved as stroke_model_optimized.pkl\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\devar\\.venv\\my_venv\\lib\\site-packages\\sklearn\\utils\\validation.py:2739: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "c:\\Users\\devar\\.venv\\my_venv\\lib\\site-packages\\sklearn\\utils\\validation.py:2739: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import joblib\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split, StratifiedKFold, GridSearchCV\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.metrics import classification_report, roc_auc_score, precision_recall_curve, confusion_matrix\n",
    "from imblearn.over_sampling import ADASYN\n",
    "from imblearn.pipeline import Pipeline as ImbPipeline\n",
    "from lightgbm import LGBMClassifier\n",
    "import seaborn as sns\n",
    "\n",
    "# Load and preprocess dataset with feature engineering\n",
    "stroke_df = pd.read_csv(r\"C:\\Users\\devar\\Downloads\\heart_project\\data\\healthcare-dataset-stroke-data.csv\")\n",
    "stroke_df = stroke_df.dropna(subset=['stroke'])\n",
    "imputer = SimpleImputer(strategy='median')\n",
    "stroke_df['bmi'] = imputer.fit_transform(stroke_df[['bmi']])\n",
    "# Add interaction term and categorize BMI\n",
    "stroke_df['age_hypertension'] = stroke_df['age'] * stroke_df['hypertension']\n",
    "stroke_df['bmi_category'] = pd.cut(stroke_df['bmi'], bins=[0, 18.5, 25, 30, 100], labels=['underweight', 'normal', 'overweight', 'obese'])\n",
    "encoded_df = pd.get_dummies(\n",
    "    stroke_df.drop(['id'], axis=1),\n",
    "    columns=['gender', 'ever_married', 'work_type', 'Residence_type', 'smoking_status', 'bmi_category'],\n",
    "    drop_first=True\n",
    ")\n",
    "X = encoded_df.drop('stroke', axis=1)\n",
    "y = encoded_df['stroke']\n",
    "# Remove low-importance features from previous run\n",
    "low_importance_features = ['gender_Other', 'work_type_Never_worked', 'bmi', 'avg_glucose_level']\n",
    "X = X.drop(columns=[col for col in low_importance_features if col in X.columns])\n",
    "scaler = StandardScaler()\n",
    "X_scaled = pd.DataFrame(scaler.fit_transform(X), columns=X.columns)\n",
    "X_scaled['stroke'] = y\n",
    "X_scaled.to_csv(\"stroke_processed.csv\", index=False)\n",
    "joblib.dump(scaler, \"scaler_stroke.pkl\")\n",
    "joblib.dump(imputer, \"imputer_stroke.pkl\")\n",
    "print(\"âœ… Stroke dataset encoded, normalized, and saved as stroke_processed.csv\")\n",
    "\n",
    "# Improved stroke model training function\n",
    "def train_stroke_model():\n",
    "    # Load processed data\n",
    "    stroke_df = pd.read_csv(\"stroke_processed.csv\")\n",
    "    X = stroke_df.drop(\"stroke\", axis=1)\n",
    "    y = stroke_df[\"stroke\"]\n",
    "\n",
    "    # Define pipeline with LightGBM\n",
    "    pipeline = ImbPipeline([\n",
    "        ('imputer', SimpleImputer(strategy='mean')),\n",
    "        ('scaler', StandardScaler()),\n",
    "        ('adasyn', ADASYN(random_state=42, sampling_strategy=0.4)),  # Reduced sampling ratio\n",
    "        ('model', LGBMClassifier(random_state=42, is_unbalance=True))\n",
    "    ])\n",
    "\n",
    "    # Hyperparameter grid for LightGBM\n",
    "    param_grid = {\n",
    "        'model__n_estimators': [100, 200],\n",
    "        'model__max_depth': [3, 6, 10],\n",
    "        'model__learning_rate': [0.01, 0.1],\n",
    "        'model__num_leaves': [31, 50],\n",
    "        'model__min_child_samples': [20, 30],\n",
    "        'model__subsample': [0.7, 1.0]\n",
    "    }\n",
    "\n",
    "    # Stratified K-Fold Cross-Validation\n",
    "    cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "    grid_search = GridSearchCV(\n",
    "        pipeline, param_grid, cv=cv, scoring=['f1_macro', 'roc_auc'], refit='f1_macro', n_jobs=-1, verbose=1, return_train_score=True\n",
    "    )\n",
    "\n",
    "    # Split data\n",
    "    X_train, X_test, y_train, y_test = train_test_split(\n",
    "        X, y, stratify=y, test_size=0.2, random_state=42\n",
    "    )\n",
    "\n",
    "    # Fit model with hyperparameter tuning\n",
    "    grid_search.fit(X_train, y_train)\n",
    "    best_model = grid_search.best_estimator_\n",
    "    print(\"\\nðŸ§  Best Parameters:\", grid_search.best_params_)\n",
    "    print(\"\\nðŸ§  Cross-Validation F1-Macro Score: {:.3f} Â± {:.3f}\".format(\n",
    "        grid_search.best_score_, grid_search.cv_results_['std_test_f1_macro'][grid_search.best_index_]\n",
    "    ))\n",
    "    print(\"\\nðŸ§  Cross-Validation ROC AUC Score: {:.3f} Â± {:.3f}\".format(\n",
    "        grid_search.cv_results_['mean_test_roc_auc'][grid_search.best_index_],\n",
    "        grid_search.cv_results_['std_test_roc_auc'][grid_search.best_index_]\n",
    "    ))\n",
    "\n",
    "    # Feature importance\n",
    "    feature_importances = best_model.named_steps['model'].feature_importances_\n",
    "    feature_imp_df = pd.DataFrame({\n",
    "        'feature': X.columns,\n",
    "        'importance': feature_importances / feature_importances.sum()  # Normalize\n",
    "    }).sort_values('importance', ascending=False)\n",
    "    print(\"\\nðŸ§  Feature Importances:\\n\", feature_imp_df)\n",
    "\n",
    "    # Evaluate model (default threshold)\n",
    "    y_pred = best_model.predict(X_test)\n",
    "    print(\"\\nðŸ§  Stroke Model Performance (Default Threshold):\")\n",
    "    print(classification_report(y_test, y_pred))\n",
    "    print(\"\\nðŸ§  Confusion Matrix (Default Threshold):\")\n",
    "    print(confusion_matrix(y_test, y_pred))\n",
    "\n",
    "    # Improved threshold tuning\n",
    "    y_probs = best_model.predict_proba(X_test)[:, 1]\n",
    "    precision, recall, thresholds = precision_recall_curve(y_test, y_probs)\n",
    "    # Select threshold where recall >= 0.65 and maximize F1-score\n",
    "    f1_scores = 2 * (precision * recall) / (precision + recall + 1e-10)\n",
    "    valid_indices = np.where(recall >= 0.65)[0]\n",
    "    if len(valid_indices) > 0:\n",
    "        optimal_idx = valid_indices[np.argmax(f1_scores[valid_indices])]\n",
    "        optimal_threshold = thresholds[optimal_idx]\n",
    "    else:\n",
    "        optimal_idx = np.argmax(f1_scores)\n",
    "        optimal_threshold = thresholds[optimal_idx]\n",
    "    y_pred_adjusted = (y_probs >= optimal_threshold).astype(int)\n",
    "    print(\"\\nðŸ§  Stroke Model with Adjusted Threshold (Recall >= 0.65):\")\n",
    "    print(classification_report(y_test, y_pred_adjusted))\n",
    "    print(\"\\nðŸ§  Confusion Matrix (Adjusted Threshold):\")\n",
    "    print(confusion_matrix(y_test, y_pred_adjusted))\n",
    "    print(f\"Optimal Threshold: {optimal_threshold:.3f}\")\n",
    "    print(f\"ROC AUC Score: {roc_auc_score(y_test, y_probs):.3f}\")\n",
    "\n",
    "    # Plot Precision-Recall Curve\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    plt.plot(recall, precision, label='Precision-Recall Curve')\n",
    "    plt.scatter(recall[optimal_idx], precision[optimal_idx], color='red', label=f'Optimal Threshold ({optimal_threshold:.3f})')\n",
    "    plt.xlabel('Recall')\n",
    "    plt.ylabel('Precision')\n",
    "    plt.title('Precision-Recall Curve')\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "    plt.savefig('precision_recall_curve.png')\n",
    "    plt.close()\n",
    "    print(\"âœ… Precision-Recall curve saved as precision_recall_curve.png\")\n",
    "\n",
    "    # Save the best model\n",
    "    joblib.dump(best_model, \"stroke_model_optimized.pkl\")\n",
    "    print(\"âœ… Optimized stroke model saved as stroke_model_optimized.pkl\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    train_stroke_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1532dd96",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ML Kernel",
   "language": "python",
   "name": "ml-kernel"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
